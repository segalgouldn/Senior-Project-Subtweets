{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtweets Downloader Jupyter Notebook-in-Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals:\n",
    "#### Create a corpus of subtweets for use in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods:\n",
    "#### Twitter API searching: When a user uses the phrase \"subtweet\" in a reply to a Tweet, the original Tweet which all the replies in that thread address is probably an actual subtweet. The Twitter API makes it possible to find such Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries for Twitter API access, tables, and text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up access to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key, consumer_secret, access_token, access_token_secret = open(\"credentials.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifically take advantage of built-in methods to handle Twitter API rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursively find the last Tweet in a chain of replies which is not in reply to any other Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_tweet(tweet_id):\n",
    "    tweet = api.get_status(tweet_id)\n",
    "    try:\n",
    "        return first_tweet(tweet._json[\"in_reply_to_status_id\"])\n",
    "    except tweepy.TweepError:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify some parameters for the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\\\"subtweet\\\" since:2016-12-01\"\n",
    "max_tweets = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a list of all Tweets matching the search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 725\n",
      "Rate limit reached. Sleeping for: 875\n",
      "Rate limit reached. Sleeping for: 874\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "CPU times: user 9.93 s, sys: 600 ms, total: 10.5 s\n",
      "Wall time: 1h 58min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "statuses = []\n",
    "for status in tweepy.Cursor(api.search, q=query, lang=\"en\").items(max_tweets):\n",
    "    # The status must be a reply\n",
    "    try:\n",
    "        if status._json[\"in_reply_to_status_id\"]:\n",
    "            statuses.append(status)\n",
    "        else:\n",
    "            continue\n",
    "    except tweepy.TweepError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(statuses, open(\"statuses.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#statuses = pickle.load(open(\"statuses.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statuses acquired: 5417\n"
     ]
    }
   ],
   "source": [
    "print(\"Statuses acquired: \" + str(len(statuses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Tweets which do not contain the exact search term \"subtweet.\" Apparently, Tweepy grabs extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statuses = [status for status in statuses if \"subtweet\" in status._json[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statuses actually containing \"subtweet\": 4660\n"
     ]
    }
   ],
   "source": [
    "print(\"Statuses actually containing \\\"subtweet\\\": \" + str(len(statuses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the list into a dictionary for use in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "accuser_usernames = []\n",
    "subtweet_evidences = []\n",
    "subtweet_evidence_ids = []\n",
    "subtweeter_usernames = []\n",
    "alleged_subtweets = []\n",
    "alleged_subtweet_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 794\n",
      "Rate limit reached. Sleeping for: 792\n",
      "Rate limit reached. Sleeping for: 793\n",
      "Rate limit reached. Sleeping for: 790\n",
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 788\n",
      "Rate limit reached. Sleeping for: 785\n",
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 784\n",
      "Rate limit reached. Sleeping for: 786\n",
      "Rate limit reached. Sleeping for: 785\n",
      "Rate limit reached. Sleeping for: 790\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 788\n",
      "Rate limit reached. Sleeping for: 790\n",
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 787\n",
      "CPU times: user 4min 13s, sys: 10.7 s, total: 4min 23s\n",
      "Wall time: 5h 17min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(statuses)):\n",
    "    status = statuses[i]._json\n",
    "    \n",
    "    user = status[\"user\"][\"screen_name\"]\n",
    "    tweet_text = status[\"text\"]\n",
    "    tweet_id = status[\"id\"]\n",
    "    \n",
    "    #print(str(i+1) + \": \" + tweet_text)\n",
    "    \n",
    "    accuser_usernames.append(user)\n",
    "    subtweet_evidences.append(tweet_text)\n",
    "    subtweet_evidence_ids.append(tweet_id)\n",
    "    try:\n",
    "        first = first_tweet(tweet_id)._json\n",
    "        first_user = first[\"user\"][\"screen_name\"]\n",
    "        first_text = first[\"text\"]\n",
    "        first_id = first[\"id\"]\n",
    "        if first_user != user: # Confirm a user is not reply to itself\n",
    "            subtweeter_usernames.append(first_user)\n",
    "            alleged_subtweets.append(first_text)\n",
    "            alleged_subtweet_ids.append(first_id)\n",
    "        else:\n",
    "            del accuser_usernames[-1]\n",
    "            del subtweet_evidences[-1]\n",
    "            del subtweet_evidence_ids[-1]\n",
    "    except tweepy.TweepError:\n",
    "        del accuser_usernames[-1]\n",
    "        del subtweet_evidences[-1]\n",
    "        del subtweet_evidence_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict = {\"accuser_username\": accuser_usernames, \n",
    "           \"subtweet_evidence\": subtweet_evidences, \n",
    "           \"subtweet_evidence_id\": subtweet_evidence_ids, \n",
    "           \"subtweeter_username\": subtweeter_usernames,\n",
    "           \"alleged_subtweet\": alleged_subtweets,\n",
    "           \"alleged_subtweet_id\": alleged_subtweet_ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows from the dataframe for which the associated Tweet contains a user mention, the phrase \"subtweet,\" or is too short to be a subtweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict_copy = {\"accuser_username\": [], \n",
    "                \"subtweet_evidence\": [], \n",
    "                \"subtweet_evidence_id\": [], \n",
    "                \"subtweeter_username\": [],\n",
    "                \"alleged_subtweet\": [],\n",
    "                \"alleged_subtweet_id\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'(?:http|ftp|https)://(?:[\\w_-]+(?:(?:\\.[\\w_-]+)+))(?:[\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71 ms, sys: 0 ns, total: 71 ms\n",
      "Wall time: 70.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(df_dict[\"alleged_subtweet\"])):\n",
    "    if (\"@\" not in df_dict[\"alleged_subtweet\"][i] and # Subtweets should not contain mentions\n",
    "        not pattern.findall(df_dict[\"alleged_subtweet\"][i]) and # Subtweets should not contain URLs\n",
    "        \"subtweet\" not in df_dict[\"alleged_subtweet\"][i] and # Subtweets which call themselves subtweets... aren't\n",
    "        len(tokenizer.tokenize(df_dict[\"alleged_subtweet\"][i])) > 5): # Arbitrarily only count longer Tweets\n",
    "        #print(str(i))\n",
    "        df_dict_copy[\"accuser_username\"].append(df_dict[\"accuser_username\"][i])\n",
    "        df_dict_copy[\"subtweet_evidence\"].append(df_dict[\"subtweet_evidence\"][i])\n",
    "        df_dict_copy[\"subtweet_evidence_id\"].append(df_dict[\"subtweet_evidence_id\"][i])\n",
    "        df_dict_copy[\"subtweeter_username\"].append(df_dict[\"subtweeter_username\"][i])\n",
    "        df_dict_copy[\"alleged_subtweet\"].append(df_dict[\"alleged_subtweet\"][i])\n",
    "        df_dict_copy[\"alleged_subtweet_id\"].append(df_dict[\"alleged_subtweet_id\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm all the lists are the same length for use in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accusers (usernames): 1148\n",
      "Number of evidence Tweets (text): 1148\n",
      "Number of evidence Tweets (IDs): 1148\n",
      "Number of subtweeters (usernames): 1148\n",
      "Number of subtweets (text): 1148\n",
      "Number of subtweets (IDs): 1148\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of accusers (usernames): \" + str(len(df_dict_copy[\"accuser_username\"])))\n",
    "print(\"Number of evidence Tweets (text): \" + str(len(df_dict_copy[\"subtweet_evidence\"])))\n",
    "print(\"Number of evidence Tweets (IDs): \" + str(len(df_dict_copy[\"subtweet_evidence_id\"])))\n",
    "print(\"Number of subtweeters (usernames): \" + str(len(df_dict_copy[\"subtweeter_username\"])))\n",
    "print(\"Number of subtweets (text): \" + str(len(df_dict_copy[\"alleged_subtweet\"])))\n",
    "print(\"Number of subtweets (IDs): \" + str(len(df_dict_copy[\"alleged_subtweet_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dict_copy, columns=[\"accuser_username\", \n",
    "                                         \"subtweet_evidence\", \n",
    "                                         \"subtweet_evidence_id\", \n",
    "                                         \"subtweeter_username\", \n",
    "                                         \"alleged_subtweet\", \n",
    "                                         \"alleged_subtweet_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt to fit more of the strings in each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the top of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuser_username</th>\n",
       "      <th>subtweet_evidence</th>\n",
       "      <th>subtweet_evidence_id</th>\n",
       "      <th>subtweeter_username</th>\n",
       "      <th>alleged_subtweet</th>\n",
       "      <th>alleged_subtweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>    Way_too_lazy</td>\n",
       "      <td> @IlluminatifyRBX @SirDeviloper The only tweet he didn't subtweet me in was when he taunted me cause he almost had t… https://t.co/awIH2iWIPa</td>\n",
       "      <td> 946336513117257728</td>\n",
       "      <td> IlluminatifyRBX</td>\n",
       "      <td>                                                                         i have to be honest im glad fireable was suspended, he deserved it</td>\n",
       "      <td> 946328768359972864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> DexterAlmighty9</td>\n",
       "      <td>                                                                                                               @Biltawulf Is this a subtweet?</td>\n",
       "      <td> 946333445998997507</td>\n",
       "      <td>       Biltawulf</td>\n",
       "      <td>             If you’re tweeting details of your Twitter family then it’s time to put your phone down, go outside and speak to adult humans.</td>\n",
       "      <td> 946317847558533121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>    VannaMaKayla</td>\n",
       "      <td>                                                               @lifewithkady 🙄🙄 don’t have to subtweet when our elbows are literally touching</td>\n",
       "      <td> 946328159426875392</td>\n",
       "      <td>    lifewithkady</td>\n",
       "      <td>                                                                                                               Don’t mind Savannah, y’all 😂</td>\n",
       "      <td> 946327651685470208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>          bubsby</td>\n",
       "      <td>                                                                                          @Moomishii y u gotta subtweet @NasuFriend like that</td>\n",
       "      <td> 946323669978046464</td>\n",
       "      <td>       Moomishii</td>\n",
       "      <td> twitter trap: (picture of a cat rolling on the floor and eating spaghetti)\\n\\nalso twitter trap: i want a boyfriend that tears out my eyes</td>\n",
       "      <td> 946225427026268161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>      JessSchmes</td>\n",
       "      <td>                                                          @jtbaxa YES YOU DO AND MORE. FUCK DA HOE. #subtweet #iknowyouseethisbitch #comeatme</td>\n",
       "      <td> 946319036794650624</td>\n",
       "      <td>          jtbaxa</td>\n",
       "      <td>                                                                                                               I honestly deserve the best.</td>\n",
       "      <td> 946261637920522240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuser_username  \\\n",
       "0     Way_too_lazy   \n",
       "1  DexterAlmighty9   \n",
       "2     VannaMaKayla   \n",
       "3           bubsby   \n",
       "4       JessSchmes   \n",
       "\n",
       "                                                                                                                              subtweet_evidence  \\\n",
       "0  @IlluminatifyRBX @SirDeviloper The only tweet he didn't subtweet me in was when he taunted me cause he almost had t… https://t.co/awIH2iWIPa   \n",
       "1                                                                                                                @Biltawulf Is this a subtweet?   \n",
       "2                                                                @lifewithkady 🙄🙄 don’t have to subtweet when our elbows are literally touching   \n",
       "3                                                                                           @Moomishii y u gotta subtweet @NasuFriend like that   \n",
       "4                                                           @jtbaxa YES YOU DO AND MORE. FUCK DA HOE. #subtweet #iknowyouseethisbitch #comeatme   \n",
       "\n",
       "   subtweet_evidence_id subtweeter_username  \\\n",
       "0    946336513117257728     IlluminatifyRBX   \n",
       "1    946333445998997507           Biltawulf   \n",
       "2    946328159426875392        lifewithkady   \n",
       "3    946323669978046464           Moomishii   \n",
       "4    946319036794650624              jtbaxa   \n",
       "\n",
       "                                                                                                                             alleged_subtweet  \\\n",
       "0                                                                          i have to be honest im glad fireable was suspended, he deserved it   \n",
       "1              If you’re tweeting details of your Twitter family then it’s time to put your phone down, go outside and speak to adult humans.   \n",
       "2                                                                                                                Don’t mind Savannah, y’all 😂   \n",
       "3  twitter trap: (picture of a cat rolling on the floor and eating spaghetti)\\n\\nalso twitter trap: i want a boyfriend that tears out my eyes   \n",
       "4                                                                                                                I honestly deserve the best.   \n",
       "\n",
       "   alleged_subtweet_id  \n",
       "0   946328768359972864  \n",
       "1   946317847558533121  \n",
       "2   946327651685470208  \n",
       "3   946225427026268161  \n",
       "4   946261637920522240  \n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataframe as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"probably_subtweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
