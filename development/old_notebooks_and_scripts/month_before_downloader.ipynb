{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtweets Downloader Jupyter Notebook-in-Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals:\n",
    "#### Create a corpus of subtweets for use in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods:\n",
    "#### Twitter API searching: When a user uses the phrase \"subtweet\" in a reply to a Tweet, the original Tweet which all the replies in that thread address is probably an actual subtweet. The Twitter API makes it possible to find such Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries for Twitter API access, tables, and text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up access to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key, consumer_secret, access_token, access_token_secret = open(\"credentials.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifically take advantage of built-in methods to handle Twitter API rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursively find the last Tweet in a chain of replies which is not in reply to any other Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_tweet(tweet_id):\n",
    "    tweet = api.get_status(tweet_id)\n",
    "    try:\n",
    "        return first_tweet(tweet._json[\"in_reply_to_status_id\"])\n",
    "    except tweepy.TweepError:\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify some parameters for the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\\\"subtweet\\\" since:2016-12-01\"\n",
    "max_tweets = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a list of all Tweets matching the search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 725\n",
      "Rate limit reached. Sleeping for: 875\n",
      "Rate limit reached. Sleeping for: 874\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "Rate limit reached. Sleeping for: 873\n",
      "CPU times: user 9.93 s, sys: 600 ms, total: 10.5 s\n",
      "Wall time: 1h 58min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "statuses = []\n",
    "for status in tweepy.Cursor(api.search, q=query, lang=\"en\").items(max_tweets):\n",
    "    # The status must be a reply\n",
    "    try:\n",
    "        if status._json[\"in_reply_to_status_id\"]:\n",
    "            statuses.append(status)\n",
    "        else:\n",
    "            continue\n",
    "    except tweepy.TweepError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(statuses, open(\"statuses.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#statuses = pickle.load(open(\"statuses.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statuses acquired: 5417\n"
     ]
    }
   ],
   "source": [
    "print(\"Statuses acquired: \" + str(len(statuses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Tweets which do not contain the exact search term \"subtweet.\" Apparently, Tweepy grabs extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statuses = [status for status in statuses if \"subtweet\" in status._json[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statuses actually containing \"subtweet\": 4660\n"
     ]
    }
   ],
   "source": [
    "print(\"Statuses actually containing \\\"subtweet\\\": \" + str(len(statuses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the list into a dictionary for use in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "accuser_usernames = []\n",
    "subtweet_evidences = []\n",
    "subtweet_evidence_ids = []\n",
    "subtweeter_usernames = []\n",
    "alleged_subtweets = []\n",
    "alleged_subtweet_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 794\n",
      "Rate limit reached. Sleeping for: 792\n",
      "Rate limit reached. Sleeping for: 793\n",
      "Rate limit reached. Sleeping for: 790\n",
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 788\n",
      "Rate limit reached. Sleeping for: 785\n",
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 784\n",
      "Rate limit reached. Sleeping for: 786\n",
      "Rate limit reached. Sleeping for: 785\n",
      "Rate limit reached. Sleeping for: 790\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 788\n",
      "Rate limit reached. Sleeping for: 790\n",
      "Rate limit reached. Sleeping for: 791\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 787\n",
      "Rate limit reached. Sleeping for: 787\n",
      "CPU times: user 4min 13s, sys: 10.7 s, total: 4min 23s\n",
      "Wall time: 5h 17min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(statuses)):\n",
    "    status = statuses[i]._json\n",
    "    \n",
    "    user = status[\"user\"][\"screen_name\"]\n",
    "    tweet_text = status[\"text\"]\n",
    "    tweet_id = status[\"id\"]\n",
    "    \n",
    "    #print(str(i+1) + \": \" + tweet_text)\n",
    "    \n",
    "    accuser_usernames.append(user)\n",
    "    subtweet_evidences.append(tweet_text)\n",
    "    subtweet_evidence_ids.append(tweet_id)\n",
    "    try:\n",
    "        first = first_tweet(tweet_id)._json\n",
    "        first_user = first[\"user\"][\"screen_name\"]\n",
    "        first_text = first[\"text\"]\n",
    "        first_id = first[\"id\"]\n",
    "        if first_user != user: # Confirm a user is not reply to itself\n",
    "            subtweeter_usernames.append(first_user)\n",
    "            alleged_subtweets.append(first_text)\n",
    "            alleged_subtweet_ids.append(first_id)\n",
    "        else:\n",
    "            del accuser_usernames[-1]\n",
    "            del subtweet_evidences[-1]\n",
    "            del subtweet_evidence_ids[-1]\n",
    "    except tweepy.TweepError:\n",
    "        del accuser_usernames[-1]\n",
    "        del subtweet_evidences[-1]\n",
    "        del subtweet_evidence_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict = {\"accuser_username\": accuser_usernames, \n",
    "           \"subtweet_evidence\": subtweet_evidences, \n",
    "           \"subtweet_evidence_id\": subtweet_evidence_ids, \n",
    "           \"subtweeter_username\": subtweeter_usernames,\n",
    "           \"alleged_subtweet\": alleged_subtweets,\n",
    "           \"alleged_subtweet_id\": alleged_subtweet_ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows from the dataframe for which the associated Tweet contains a user mention, the phrase \"subtweet,\" or is too short to be a subtweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict_copy = {\"accuser_username\": [], \n",
    "                \"subtweet_evidence\": [], \n",
    "                \"subtweet_evidence_id\": [], \n",
    "                \"subtweeter_username\": [],\n",
    "                \"alleged_subtweet\": [],\n",
    "                \"alleged_subtweet_id\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'(?:http|ftp|https)://(?:[\\w_-]+(?:(?:\\.[\\w_-]+)+))(?:[\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71 ms, sys: 0 ns, total: 71 ms\n",
      "Wall time: 70.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(df_dict[\"alleged_subtweet\"])):\n",
    "    if (\"@\" not in df_dict[\"alleged_subtweet\"][i] and # Subtweets should not contain mentions\n",
    "        not pattern.findall(df_dict[\"alleged_subtweet\"][i]) and # Subtweets should not contain URLs\n",
    "        \"subtweet\" not in df_dict[\"alleged_subtweet\"][i] and # Subtweets which call themselves subtweets... aren't\n",
    "        len(tokenizer.tokenize(df_dict[\"alleged_subtweet\"][i])) > 5): # Arbitrarily only count longer Tweets\n",
    "        #print(str(i))\n",
    "        df_dict_copy[\"accuser_username\"].append(df_dict[\"accuser_username\"][i])\n",
    "        df_dict_copy[\"subtweet_evidence\"].append(df_dict[\"subtweet_evidence\"][i])\n",
    "        df_dict_copy[\"subtweet_evidence_id\"].append(df_dict[\"subtweet_evidence_id\"][i])\n",
    "        df_dict_copy[\"subtweeter_username\"].append(df_dict[\"subtweeter_username\"][i])\n",
    "        df_dict_copy[\"alleged_subtweet\"].append(df_dict[\"alleged_subtweet\"][i])\n",
    "        df_dict_copy[\"alleged_subtweet_id\"].append(df_dict[\"alleged_subtweet_id\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm all the lists are the same length for use in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accusers (usernames): 1148\n",
      "Number of evidence Tweets (text): 1148\n",
      "Number of evidence Tweets (IDs): 1148\n",
      "Number of subtweeters (usernames): 1148\n",
      "Number of subtweets (text): 1148\n",
      "Number of subtweets (IDs): 1148\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of accusers (usernames): \" + str(len(df_dict_copy[\"accuser_username\"])))\n",
    "print(\"Number of evidence Tweets (text): \" + str(len(df_dict_copy[\"subtweet_evidence\"])))\n",
    "print(\"Number of evidence Tweets (IDs): \" + str(len(df_dict_copy[\"subtweet_evidence_id\"])))\n",
    "print(\"Number of subtweeters (usernames): \" + str(len(df_dict_copy[\"subtweeter_username\"])))\n",
    "print(\"Number of subtweets (text): \" + str(len(df_dict_copy[\"alleged_subtweet\"])))\n",
    "print(\"Number of subtweets (IDs): \" + str(len(df_dict_copy[\"alleged_subtweet_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dict_copy, columns=[\"accuser_username\", \n",
    "                                         \"subtweet_evidence\", \n",
    "                                         \"subtweet_evidence_id\", \n",
    "                                         \"subtweeter_username\", \n",
    "                                         \"alleged_subtweet\", \n",
    "                                         \"alleged_subtweet_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt to fit more of the strings in each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the top of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuser_username</th>\n",
       "      <th>subtweet_evidence</th>\n",
       "      <th>subtweet_evidence_id</th>\n",
       "      <th>subtweeter_username</th>\n",
       "      <th>alleged_subtweet</th>\n",
       "      <th>alleged_subtweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>    Way_too_lazy</td>\n",
       "      <td> @IlluminatifyRBX @SirDeviloper The only tweet he didn't subtweet me in was when he taunted me cause he almost had tâ€¦ https://t.co/awIH2iWIPa</td>\n",
       "      <td> 946336513117257728</td>\n",
       "      <td> IlluminatifyRBX</td>\n",
       "      <td>                                                                         i have to be honest im glad fireable was suspended, he deserved it</td>\n",
       "      <td> 946328768359972864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> DexterAlmighty9</td>\n",
       "      <td>                                                                                                               @Biltawulf Is this a subtweet?</td>\n",
       "      <td> 946333445998997507</td>\n",
       "      <td>       Biltawulf</td>\n",
       "      <td>             If youâ€™re tweeting details of your Twitter family then itâ€™s time to put your phone down, go outside and speak to adult humans.</td>\n",
       "      <td> 946317847558533121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>    VannaMaKayla</td>\n",
       "      <td>                                                               @lifewithkady ðŸ™„ðŸ™„ donâ€™t have to subtweet when our elbows are literally touching</td>\n",
       "      <td> 946328159426875392</td>\n",
       "      <td>    lifewithkady</td>\n",
       "      <td>                                                                                                               Donâ€™t mind Savannah, yâ€™all ðŸ˜‚</td>\n",
       "      <td> 946327651685470208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>          bubsby</td>\n",
       "      <td>                                                                                          @Moomishii y u gotta subtweet @NasuFriend like that</td>\n",
       "      <td> 946323669978046464</td>\n",
       "      <td>       Moomishii</td>\n",
       "      <td> twitter trap: (picture of a cat rolling on the floor and eating spaghetti)\\n\\nalso twitter trap: i want a boyfriend that tears out my eyes</td>\n",
       "      <td> 946225427026268161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>      JessSchmes</td>\n",
       "      <td>                                                          @jtbaxa YES YOU DO AND MORE. FUCK DA HOE. #subtweet #iknowyouseethisbitch #comeatme</td>\n",
       "      <td> 946319036794650624</td>\n",
       "      <td>          jtbaxa</td>\n",
       "      <td>                                                                                                               I honestly deserve the best.</td>\n",
       "      <td> 946261637920522240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuser_username  \\\n",
       "0     Way_too_lazy   \n",
       "1  DexterAlmighty9   \n",
       "2     VannaMaKayla   \n",
       "3           bubsby   \n",
       "4       JessSchmes   \n",
       "\n",
       "                                                                                                                              subtweet_evidence  \\\n",
       "0  @IlluminatifyRBX @SirDeviloper The only tweet he didn't subtweet me in was when he taunted me cause he almost had tâ€¦ https://t.co/awIH2iWIPa   \n",
       "1                                                                                                                @Biltawulf Is this a subtweet?   \n",
       "2                                                                @lifewithkady ðŸ™„ðŸ™„ donâ€™t have to subtweet when our elbows are literally touching   \n",
       "3                                                                                           @Moomishii y u gotta subtweet @NasuFriend like that   \n",
       "4                                                           @jtbaxa YES YOU DO AND MORE. FUCK DA HOE. #subtweet #iknowyouseethisbitch #comeatme   \n",
       "\n",
       "   subtweet_evidence_id subtweeter_username  \\\n",
       "0    946336513117257728     IlluminatifyRBX   \n",
       "1    946333445998997507           Biltawulf   \n",
       "2    946328159426875392        lifewithkady   \n",
       "3    946323669978046464           Moomishii   \n",
       "4    946319036794650624              jtbaxa   \n",
       "\n",
       "                                                                                                                             alleged_subtweet  \\\n",
       "0                                                                          i have to be honest im glad fireable was suspended, he deserved it   \n",
       "1              If youâ€™re tweeting details of your Twitter family then itâ€™s time to put your phone down, go outside and speak to adult humans.   \n",
       "2                                                                                                                Donâ€™t mind Savannah, yâ€™all ðŸ˜‚   \n",
       "3  twitter trap: (picture of a cat rolling on the floor and eating spaghetti)\\n\\nalso twitter trap: i want a boyfriend that tears out my eyes   \n",
       "4                                                                                                                I honestly deserve the best.   \n",
       "\n",
       "   alleged_subtweet_id  \n",
       "0   946328768359972864  \n",
       "1   946317847558533121  \n",
       "2   946327651685470208  \n",
       "3   946225427026268161  \n",
       "4   946261637920522240  \n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataframe as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"probably_subtweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
