{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from random import choice\n",
    "from string import punctuation\n",
    "from time import sleep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import tweepy\n",
    "import enchant\n",
    "import nltk\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.4f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_pattern = r'(\\#[a-zA-Z0-9]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_pattern = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\\xab\\xbb\\u201c\\u201d\\u2018\\u2019]))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_mentions_pattern = r'(?<=^|(?<=[^a-zA-Z0-9-\\.]))@([A-Za-z0-9_]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.75 # 75% positives and higher, only\n",
    "DURATION = 60*15 # 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = joblib.load(\"../data/other_data/subtweets_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key, consumer_secret, access_token, access_token_secret = open(\"../../credentials.txt\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, retry_delay=1, timeout=120, # 2 minutes\n",
    "                 compression=True, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtweets_live_list = []\n",
    "non_subtweets_live_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        choices = [\"retweet\", \"like\", \"retweet and like\", \"reply\"]\n",
    "        \n",
    "        id_str = status.id_str\n",
    "        screen_name = status.user.screen_name\n",
    "        created_at = status.created_at\n",
    "        retweeted = status.retweeted\n",
    "        in_reply_to = status.in_reply_to_status_id\n",
    "        \n",
    "        if \"extended_tweet\" in status._json:\n",
    "            if \"full_text\" in status._json[\"extended_tweet\"]:\n",
    "                text = status._json[\"extended_tweet\"][\"full_text\"]\n",
    "            else:\n",
    "                pass # Something else?\n",
    "        elif \"text\" in status._json:\n",
    "            text = status._json[\"text\"]\n",
    "        \n",
    "        text = (re.sub(hashtags_pattern, \n",
    "                       \"➊\", \n",
    "                       re.sub(urls_pattern, \n",
    "                              \"➋\", \n",
    "                              re.sub(at_mentions_pattern, \n",
    "                                     \"➌\", \n",
    "                                     text)))\n",
    "                .replace(\"\\u2018\", \"'\")\n",
    "                .replace(\"\\u2019\", \"'\")\n",
    "                .replace(\"\\u201c\", \"\\\"\")\n",
    "                .replace(\"\\u201d\", \"\\\"\")\n",
    "                .replace(\"&quot;\", \"\\\"\")\n",
    "                .replace(\"&amp;\", \"&\")\n",
    "                .replace(\"&gt;\", \">\")\n",
    "                .replace(\"&lt;\", \"<\"))\n",
    "                \n",
    "        positive_probability = sentiment_pipeline.predict_proba([text]).tolist()[0][1]\n",
    "        \n",
    "        row = {\"tweet\": text, \n",
    "               \"screen_name\": screen_name, \n",
    "               \"time\": created_at, \n",
    "               \"subtweet_probability\": positive_probability}\n",
    "        \n",
    "        print_list = pd.DataFrame([row]).values.tolist()[0]\n",
    "        \n",
    "        if all([positive_probability >= THRESHOLD, \n",
    "                not retweeted,\n",
    "                \"RT \" not in text, \n",
    "                not in_reply_to]):\n",
    "            \n",
    "            decision = choice(choices)\n",
    "            if decision == \"retweet\":\n",
    "                api.update_status((\"Is this a subtweet? {:.3%} \\n\" + \n",
    "                                   \"https://twitter.com/{}/status/{}\").format(positive_probability, \n",
    "                                                                              screen_name, \n",
    "                                                                              id_str))\n",
    "                print(\"Retweet!\")\n",
    "            \n",
    "            if decision == \"like\":\n",
    "                api.create_favorite(id_str)\n",
    "            \n",
    "            if decision == \"retweet and like\":\n",
    "                api.update_status((\"Is this a subtweet? {:.3%} \\n\" + \n",
    "                                   \"https://twitter.com/{}/status/{}\").format(positive_probability, \n",
    "                                                                              screen_name, \n",
    "                                                                              id_str))\n",
    "                api.create_favorite(id_str)\n",
    "                print(\"Retweet and like!\")\n",
    "            \n",
    "            if decision == \"reply\":\n",
    "                api.update_status(\"@{} Is this a subtweet? {:.3%}\".format(screen_name, \n",
    "                                                                          positive_probability), \n",
    "                                  id_str)\n",
    "                print(\"Reply!\")\n",
    "            \n",
    "            subtweets_live_list.append(row)\n",
    "            subtweets_df = pd.DataFrame(subtweets_live_list).sort_values(by=\"subtweet_probability\", \n",
    "                                                                         ascending=False)\n",
    "            \n",
    "            subtweets_df.to_csv(\"../data/data_from_testing/live_downloaded_data/subtweets_live_data.csv\")\n",
    "            \n",
    "            print((\"Subtweet from @{0} (Probability of {1:.3%}):\\n\" + \n",
    "                   \"Time: {2}\\n\" + \n",
    "                   \"Tweet: {3}\\n\" +\n",
    "                   \"Total tweets acquired: {4}\\n\").format(print_list[0], \n",
    "                                                          print_list[1], \n",
    "                                                          print_list[2],\n",
    "                                                          print_list[3],\n",
    "                                                          (len(subtweets_live_list) \n",
    "                                                           + len(non_subtweets_live_list))))\n",
    "            \n",
    "            return row\n",
    "        else:\n",
    "            non_subtweets_live_list.append(row)\n",
    "            non_subtweets_df = pd.DataFrame(non_subtweets_live_list).sort_values(by=\"subtweet_probability\", \n",
    "                                                                                 ascending=False)\n",
    "            non_subtweets_df.to_csv(\"../data/data_from_testing/live_downloaded_data/non_subtweets_live_data.csv\")\n",
    "            \n",
    "            return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutuals():\n",
    "    my_followers = [str(user_id) for ids_list in \n",
    "                    tweepy.Cursor(api.followers_ids, \n",
    "                                  screen_name=\"NoahSegalGould\").pages() \n",
    "                    for user_id in ids_list]\n",
    "    my_followeds = [str(user_id) for ids_list in \n",
    "                   tweepy.Cursor(api.friends_ids, \n",
    "                                 screen_name=\"NoahSegalGould\").pages() \n",
    "                   for user_id in ids_list]\n",
    "    \n",
    "    my_mutuals = list(set(my_followers) & set(my_followeds))\n",
    "    \n",
    "    bots = [\"890031065057853440\", \"895685688582180864\", \n",
    "            \"894658603977777152\", \"970553455709446144\", \n",
    "            \"786489395519983617\", \"975981192817373184\"]\n",
    "    \n",
    "    my_mutuals = [m for m in my_mutuals if m not in bots]\n",
    "    \n",
    "    with open(\"../data/other_data/NoahSegalGould_Mutuals_ids.json\", \"w\") as outfile:\n",
    "        json.dump(my_mutuals, outfile, sort_keys=True, indent=4)\n",
    "    \n",
    "    return my_mutuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutuals_and_mutuals_mutuals_ids(mutuals_threshold=250):\n",
    "    my_mutuals = get_mutuals()\n",
    "    my_mutuals_mutuals = my_mutuals[:]\n",
    "\n",
    "    for i, mutual in enumerate(my_mutuals):\n",
    "        start_time = time()\n",
    "        user = api.get_user(user_id=mutual)\n",
    "        name = user.screen_name\n",
    "        is_protected = user.protected\n",
    "        if not is_protected:\n",
    "            mutuals_followers = []\n",
    "            followers_cursor = tweepy.Cursor(api.followers_ids, user_id=mutual).items()\n",
    "            while True:\n",
    "                try:\n",
    "                    mutuals_follower = followers_cursor.next()\n",
    "                    mutuals_followers.append(str(mutuals_follower))\n",
    "                except tweepy.TweepError:\n",
    "                    sleep(30) # 30 seconds\n",
    "                    continue\n",
    "                except StopIteration:\n",
    "                    break\n",
    "            mutuals_followeds = []\n",
    "            followeds_cursor = tweepy.Cursor(api.friends_ids, user_id=mutual).items()\n",
    "            while True:\n",
    "                try:\n",
    "                    mutuals_followed = followeds_cursor.next()\n",
    "                    mutuals_followeds.append(str(mutuals_followed))\n",
    "                except tweepy.TweepError:\n",
    "                    sleep(30) # 30 seconds\n",
    "                    continue\n",
    "                except StopIteration:\n",
    "                    break\n",
    "            mutuals_mutuals = list(set(mutuals_followers) & set(mutuals_followeds))\n",
    "            print(\"{} mutuals for mutual {}: {}\".format(len(mutuals_mutuals), i+1, name))\n",
    "            if len(mutuals_mutuals) <= mutuals_threshold: # Ignore my mutuals if they have a lot of mutuals\n",
    "                my_mutuals_mutuals.extend(mutuals_mutuals)\n",
    "            else:\n",
    "                print(\"\\tSkipping: {}\".format(name))\n",
    "        else:\n",
    "            continue\n",
    "        end_time = time()\n",
    "        with open(\"../data/other_data/NoahSegalGould_Mutuals_and_Mutuals_Mutuals_ids.json\", \"w\") as outfile:\n",
    "            json.dump(my_mutuals_mutuals, outfile, sort_keys=True, indent=4)\n",
    "        print((\"{0:.2f} seconds for getting the mutuals' IDs of mutual {1}: {2}\\n\")\n",
    "              .format((end_time - start_time), i+1, name))\n",
    "    my_mutuals_mutuals = [str(mu) for mu in sorted([int(m) for m in list(set(my_mutuals_mutuals))])]\n",
    "    with open(\"../data/other_data/NoahSegalGould_Mutuals_and_Mutuals_Mutuals_ids.json\", \"w\") as outfile:\n",
    "        json.dump(my_mutuals_mutuals, outfile, indent=4)\n",
    "    return my_mutuals_mutuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# my_mutuals_mutuals = get_mutuals_and_mutuals_mutuals_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mutuals_mutuals = json.load(open(\"../data/other_data/NoahSegalGould_Mutuals_and_Mutuals_Mutuals_ids.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of my mutuals and my mutuals' mutuals: 4218\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of my mutuals and my mutuals' mutuals: {}\".format(len(my_mutuals_mutuals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_listener = StreamListener()\n",
    "stream = tweepy.Stream(auth=api.auth, listener=stream_listener, tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming has started.\n",
      "CPU times: user 13.6 s, sys: 2.18 s, total: 15.7 s\n",
      "Wall time: 15min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# stream.filter(locations=[-73.920176, 42.009637, -73.899739, 42.033421], \n",
    "# stall_warnings=True, languages=[\"en\"], async=True)\n",
    "stream.filter(follow=my_mutuals_mutuals, stall_warnings=True, languages=[\"en\"], async=True)\n",
    "print(\"Streaming has started.\")\n",
    "sleep(DURATION)\n",
    "stream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtweets_df = pd.read_csv(\"../data/data_from_testing/live_downloaded_data/subtweets_live_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>subtweet_probability</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MyBrooklynBoy</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>2018-04-18 05:44:29</td>\n",
       "      <td>Slam dunk Ross Gellar on the trash can.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     screen_name  subtweet_probability                 time  \\\n",
       "0  MyBrooklynBoy                0.7682  2018-04-18 05:44:29   \n",
       "\n",
       "                                     tweet  \n",
       "0  Slam dunk Ross Gellar on the trash can.  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtweets_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
